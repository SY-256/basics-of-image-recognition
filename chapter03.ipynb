{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4ukL0NInfyhYtjJxr4E/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SY-256/basics-of-image-recognition/blob/main/chapter03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h7TfWl4lvAW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed513428-9712-448a-f024-43451216823b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 畳み込みニューラルネットワーク"
      ],
      "metadata": {
        "id": "ZiYDeElfkUhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/colab-notebooks/basics-of-image-recognition/\""
      ],
      "metadata": {
        "id": "_m1WAKlGvtsI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def im2col(img, h, w, stride=1, pad=0):\n",
        "    \"\"\"\n",
        "    畳み込みフィルタ\n",
        "    img: (B, C, H, W)\n",
        "    h: kernel size\n",
        "    w: kernel width\n",
        "    \"\"\"\n",
        "    B, C, H, W = img.shape\n",
        "    img = np.pad(img, [(0, 0), (0, 0), (pad, pad), (pad, pad)], \"constant\")\n",
        "    out_h = (H + 2*pad - h)//stride + 1\n",
        "    out_w = (W + 2*pad - w)//stride + 1\n",
        "\n",
        "    out = np.zeros((B, C, h, w, out_h, out_w))\n",
        "\n",
        "    for y in range(h):\n",
        "        y_ = y + stride*out_h\n",
        "        for x in range(w):\n",
        "            x_ = x + stride*out_w\n",
        "            out[:, :, y, x, :, :] = img[:, :, y:y_:stride, x:x_:stride]\n",
        "\n",
        "    out = out.transpose(0, 4, 5, 1, 2, 3).reshape(B*out_h*out_w, -1)\n",
        "    return out\n",
        "\n",
        "class Conv2D:\n",
        "    \"\"\"\n",
        "    in_ch: number of input channels\n",
        "    out_ch: number of output channels\n",
        "    h, w: kernel size\n",
        "    stride: stride of conv process\n",
        "    pad: padding size\n",
        "    img: input image (B, in_ch, H, W)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch, h, w, stride=1, pad=0):\n",
        "        self.out_ch = out_ch\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "        self.filters = np.random.randn(out_ch, in_ch, h, w)\n",
        "        self.bias = np.zeros(out_ch)\n",
        "\n",
        "    def forward(self, img):\n",
        "        B, in_ch, H, W = img.shape\n",
        "        out_ch, in_ch, h, w = self.filters.shape\n",
        "\n",
        "        img = im2col(img, h, w, self.stride, self.pad)\n",
        "        filters = self.filters.reshape(out_ch, -1).T\n",
        "\n",
        "        out = np.dot(img, filters) + self.bias\n",
        "\n",
        "        out_h = 1 + int((H + 2*self.pad - h) / self.stride)\n",
        "        out_w = 1 + int((W + 2*self.pad - w) / self.stride)\n",
        "        out = out.reshape(B, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wBYmbMmEkfkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### edeg detection\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "img = Image.open(base_path + \"keyboard.png\").convert(\"L\")\n",
        "img = np.array(img, dtype=float) / 255\n",
        "img = img[np.newaxis, np.newaxis, :, :]\n",
        "conv = Conv2D(in_ch=1, out_ch=1, h=3, w=3, stride=1, pad=1)\n",
        "### horizontal edge detectio\n",
        "conv.filters[0, 0, :, :] = np.array([[-1, -2, -1], [0 ,0, 0], [1, 2, 1]])\n",
        "conv.filters[0, 0, :, :] = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "out = conv.forward(img)\n",
        "out = np.clip(out, 0, 1)\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(img[0, 0], cmap=\"gray\")\n",
        "plt.title(\"Input Image\")\n",
        "plt.subplot(122)\n",
        "plt.imshow(out[0, 0], cmap=\"gray\")\n",
        "plt.title(\"Output Image\")\n",
        "plt.savefig(base_path + \"convoled_output.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zju2EGznq9bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAP（グローバルアベレージプーリング）をスクラッチで"
      ],
      "metadata": {
        "id": "H90ikwJStdke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### GAP（グローバルアベレージプーリング）\n",
        "import numpy as np\n",
        "\n",
        "def global_average_poooling_2d(x):\n",
        "    \"\"\"\n",
        "    Global Average Pooling 2D\n",
        "\n",
        "    Args:\n",
        "        x: 入力テンソル（batch, hight, width, channels）または（height, width, chnnels）\n",
        "    Returns:\n",
        "        出力テンソル（batch_size, channels）または（channels,）\n",
        "    \"\"\"\n",
        "    if x.ndim == 4: # バッチあり\n",
        "        return np.mean(x, axis=(1,2))\n",
        "    elif x.ndim == 3: # バッチなしの場合\n",
        "        return np.mean(x, axis=(0, 1))\n",
        "    else:\n",
        "        raise ValueError(\"入力次元は3次元または4次元である必要があります\")\n",
        "\n",
        "def global_average_poooling_1d(x):\n",
        "    \"\"\"\n",
        "    Global Average Pooling 1D\n",
        "\n",
        "    Args:\n",
        "        x: 入力テンソル（batch_size, length, channels）または（lenght, channels）\n",
        "\n",
        "    Returns:\n",
        "        出力テンソル（batch_size, channels）または（channels,）\n",
        "    \"\"\"\n",
        "    if x.ndim == 3: # バッチあり\n",
        "        return np.mean(x, axis=1)\n",
        "    elif x.ndim == 2: # バッチなし\n",
        "        return np.mean(x, axis=0)\n",
        "    else:\n",
        "        raise ValueError(\"入力は2次元または3次元である必要があります\")\n",
        "\n",
        "class GlobalAveragePooling2D:\n",
        "    \"\"\"クラス版のGlobal Average Pooling 2D\"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.input_shape = x.shape\n",
        "        return global_average_poooling_2d(x)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        \"\"\"逆伝播の実装\"\"\"\n",
        "        if len(self.input_shape) == 4:\n",
        "            batch_size, height, width, channels = self.input_shape\n",
        "            # 勾配を元の形状に戻す（平均で割った値を全ピクセルに分散）\n",
        "            grad_input = np.zeros(self.input_shape)\n",
        "            for i in range(batch_size):\n",
        "                for c in range(channels):\n",
        "                    grad_input[i, :, :, c] = grad_output[i, c] / (height * width)\n",
        "\n",
        "        else:\n",
        "            height, width, channels = self.input_shape\n",
        "            grad_input = np.zeros(self.input_shape)\n",
        "            for c in range(channels):\n",
        "                grad_input[:, :, c] = grad_output[c] / (height * width)\n",
        "\n",
        "        return grad_input\n"
      ],
      "metadata": {
        "id": "Kwn_3cPku_RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Global Average Pooling 2D ===\")\n",
        "# 単一画像の場合（height=4, width=4, channels=3）\n",
        "x_2d = np.random.randn(4, 4, 3)\n",
        "print(f\"入力形状: {x_2d.shape}\")\n",
        "print(f\"入力値: {x_2d}\")\n",
        "\n",
        "output_2d = global_average_poooling_2d(x_2d)\n",
        "print(f\"出力形状: {output_2d.shape}\")\n",
        "print(f\"出力値: {output_2d}\")\n",
        "\n",
        "# バッチの場合（batch=2, height=4, width=4, channels=3）\n",
        "x_batch_2d = np.random.randn(2, 4, 4, 3)\n",
        "print(f\"\\n入力バッチ形状: {x_batch_2d.shape}\")\n",
        "\n",
        "output_batch_2d = global_average_poooling_2d(x_batch_2d)\n",
        "print(f\"バッチ出力形状: {output_batch_2d.shape}\")\n",
        "\n",
        "print(\"\\n==== クラス版 ====\")\n",
        "gap_layer = GlobalAveragePooling2D()\n",
        "\n",
        "x_test = np.random.randn(1, 3, 3, 2)\n",
        "output = gap_layer.forward(x_test)\n",
        "print(f\"入力形状: {x_test.shape}\")\n",
        "print(f\"出力形状: {output.shape}\")\n",
        "\n",
        "# 逆伝播のテスト\n",
        "grad_output = np.ones_like(output)\n",
        "grad_input = gap_layer.backward(grad_output)\n",
        "print(f\"勾配入力形状: {grad_input.shape}\")\n",
        "print(f\"勾配値の例: {grad_input[0, 0, 0, :]}\")\n"
      ],
      "metadata": {
        "id": "c3u6P_yduurO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47c4299-a141-4ff3-e89b-670702c41d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Global Average Pooling 2D ===\n",
            "入力形状: (4, 4, 3)\n",
            "入力値: [[[ 1.9216899   0.76574373  0.19227038]\n",
            "  [ 0.90747202 -1.00150843 -0.93774835]\n",
            "  [ 0.45887446  1.36584178 -0.61927072]\n",
            "  [ 0.66800848 -0.97647051 -0.8558606 ]]\n",
            "\n",
            " [[ 1.51556905 -0.81584812  1.353832  ]\n",
            "  [ 0.82094649 -1.34260133 -0.19318977]\n",
            "  [-0.7527346   1.99628424 -1.3232735 ]\n",
            "  [-0.76252744  1.4831022   1.13187252]]\n",
            "\n",
            " [[ 1.33507294  1.27968203  0.43559142]\n",
            "  [ 0.19062981  0.41805862 -0.30810173]\n",
            "  [-0.94957467 -0.17696031  0.8310906 ]\n",
            "  [ 0.57156049 -0.66808225 -1.60692287]]\n",
            "\n",
            " [[-1.21114089  1.37205759 -0.22141397]\n",
            "  [-0.19499464  0.24747499 -0.61352329]\n",
            "  [ 0.11728387  0.46471609  0.68810329]\n",
            "  [ 0.42640274  1.00966312 -0.35621508]]]\n",
            "出力形状: (3,)\n",
            "出力値: [ 0.31640863  0.33882209 -0.15017248]\n",
            "\n",
            "入力バッチ形状: (2, 4, 4, 3)\n",
            "バッチ出力形状: (2, 3)\n",
            "\n",
            "==== クラス版 ====\n",
            "入力形状: (1, 3, 3, 2)\n",
            "出力形状: (1, 2)\n",
            "勾配入力形状: (1, 3, 3, 2)\n",
            "勾配値の例: [0.11111111 0.11111111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 残差学習をスクラッチで"
      ],
      "metadata": {
        "id": "igfBbkAis3ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def relu(x):\n",
        "    \"\"\"ReLU活計化関数\"\"\"\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def conv2d(x, weights, bias=None, stride=1, padding=0):\n",
        "    \"\"\"2D畳み込み（簡易版）\"\"\"\n",
        "    batch_size, in_height, in_width, in_channels = x.shape\n",
        "    out_channels, kernel_h, kernel_w, _ = weights.shape\n",
        "\n",
        "    # パディング\n",
        "    if padding > 0:\n",
        "        x = np.pad(x, ((0, 0), (padding, padding), (padding, padding), (0, 0,)), \"constant\")\n",
        "\n",
        "    out_height = (x.shape[1] - kernel_h) // stride + 1\n",
        "    out_width = (x.shape[2] - kernel_w) // stride + 1\n",
        "\n",
        "    output = np.zeros((batch_size, out_height, out_width, out_channels))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for oc in range(out_channels):\n",
        "            for oh in range(out_height):\n",
        "                for ow in range(out_width):\n",
        "                    h_start = oh * stride\n",
        "                    w_start = ow * stride\n",
        "                    patch = x[b, h_start:h_start+kernel_h, w_start:w_start+kernel_w, :]\n",
        "                    output[b, oh, ow, oc] = np.sum(patch * weights[oc]) + (bias[oc] if bias is not None else 0)\n",
        "    return output\n",
        "\n",
        "def batch_norm(x, gamma, beta, eps=1e-5):\n",
        "    \"\"\"バッチ正規化\"\"\"\n",
        "    mean = np.mean(x, axis=(0, 1, 2), keepdims=True)\n",
        "    var = np.var(x, axis=(0, 1, 2), keepdims=True)\n",
        "    x_norm = (x - mean) / np.sqrt(var + eps)\n",
        "    return gamma * x_norm + beta\n",
        "\n",
        "class BasicBlock:\n",
        "    \"\"\"ResNetの基本ブロック（2層）\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # 畳み込み層の重み初期化\n",
        "        self.conv1d_weights = np.random.randn(out_channels, 3, 3, in_channels) * 0.1\n",
        "        self.conv1d_bias = np.zeros(out_channels)\n",
        "\n",
        "        self.conv2d_weights = np.random.randn(out_channels, 3, 3, out_channels) * 0.1\n",
        "        self.conv2d_bias = np.zeros(out_channels)\n",
        "\n",
        "        # バッチ正規化パラメータ\n",
        "        self.bn1_gamma = np.ones(out_channels)\n",
        "        self.bn1_beta = np.zeros(out_channels)\n",
        "        self.bn2_gamma = np.ones(out_channels)\n",
        "        self.bn2_beta = np.zeros(out_channels)\n",
        "\n",
        "        # ショートカット接続（チャネル数が変わる場合）\n",
        "        self.use_shortcut_conv = (stride != 1) or (in_channels != out_channels)\n",
        "        if self.use_shortcut_conv:\n",
        "            self.shortcut_weights = np.random.randn(out_channels, 1, 1, in_channels) * 0.1\n",
        "            self.shortcut_bias = np.zeros(out_channels)\n",
        "            self.shortcut_bn_gamma = np.ones(out_channels)\n",
        "            self.shortcut_bn_beta = np.zeros(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"順伝播\"\"\"\n",
        "        identity = x\n",
        "\n",
        "        # メインパス\n",
        "        out = conv2d(x, self.conv1d_weights, self.conv1d_bias, stride=self.stride, padding=1)\n",
        "        out = batch_norm(out, self.bn1_gamma, self.bn1_beta)\n",
        "        out = relu(out)\n",
        "\n",
        "        out = conv2d(out, self.conv2d_weights, self.conv2d_bias, stride=1, padding=1)\n",
        "        out = batch_norm(out, self.bn2_gamma, self.bn2_beta)\n",
        "\n",
        "        # ショートカット接続\n",
        "        if self.use_shortcut_conv:\n",
        "            identity = conv2d(identity, self.shortcut_weights, self.shortcut_bias,\n",
        "                              stride=self.stride, padding=0)\n",
        "            identity = batch_norm(identity, self.shortcut_bn_gamma, self.shortcut_bn_beta)\n",
        "\n",
        "        # 残差接続\n",
        "        out = out + identity\n",
        "        out = relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SimpleResNet:\n",
        "    \"\"\"シンプルなResNet\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # 初期畳み込み層\n",
        "        self.conv1d_weights = np.random.randn(64, 7, 7, 3) * 0.1\n",
        "        self.conv1d_bias = np.zeros(64)\n",
        "        self.bn1_gamma = np.ones(64)\n",
        "        self.bn1_beta = np.zeros(64)\n",
        "\n",
        "        # 残差ブロック\n",
        "        self.layer1 = [BasicBlock(64, 64) for _ in range(2)]\n",
        "        self.layer2 = [BasicBlock(64, 128, stride=2)] + [BasicBlock(128, 128) for _ in range(1)]\n",
        "        self.layer3 = [BasicBlock(128, 256, stride=2)] + [BasicBlock(256, 256) for _ in range(1)]\n",
        "\n",
        "        # 分類層\n",
        "        self.fc_weights = np.random.randn(256, num_classes) * 0.1\n",
        "        self.fc_bias = np.zeros(num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"順伝播\"\"\"\n",
        "        # 初期畳み込み\n",
        "        out = conv2d(x, self.conv1d_weights, self.conv1d_bias, stride=2, padding=3)\n",
        "        out = batch_norm(out, self.bn1_gamma, self.bn1_beta)\n",
        "        out = relu(out)\n",
        "\n",
        "        # 残差ブロック\n",
        "        for block in self.layer1:\n",
        "            out = block.forward(out)\n",
        "\n",
        "        for block in self.layer2:\n",
        "            out = block.forward(out)\n",
        "\n",
        "        for block in self.layer3:\n",
        "            out = block.forward(out)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        out = np.mean(out, axis=(1, 2))\n",
        "\n",
        "        # 全結合層\n",
        "        out = np.dot(out, self.fc_weights) + self.fc_bias\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "iUNsmYLUtpB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータ\n",
        "batch_size = 2\n",
        "x = np.random.randn(batch_size, 32, 32, 3)\n",
        "\n",
        "print(\"=== BasicBlockテスト ===\")\n",
        "basic_block = BasicBlock(3, 64, stride=1)\n",
        "output_basic = basic_block.forward(x)\n",
        "print(f\"入力形状: {x.shape}\")\n",
        "print(f\"BasicBlock出力形状: {output_basic.shape}\")\n",
        "\n",
        "print(\"\\n=== SimpleResNet ===\")\n",
        "model = SimpleResNet(num_classes=10)\n",
        "output = model.forward(x)\n",
        "print(f\"ResNet出力形状: {output.shape}\")\n",
        "print(f\"出力例: {output[0][:5]}\") # 最初のサンプルの最初の5クラス\n",
        "\n",
        "# 残差接続の効果を確認\n",
        "print(\"\\n=== 残差接続の効果確認 ===\")\n",
        "# 同じ入力に対して複数回実行（実際の学習では勾配が流れやすくなる）\n",
        "x_test = np.random.randn(1, 8, 8, 64)\n",
        "block_test = BasicBlock(64, 64)\n",
        "\n",
        "# 入力と出力の差分（残差）を確認\n",
        "output_test = block_test.forward(x_test)\n",
        "residual = output_test - x_test # これが学習される残差\n",
        "print(f\"入力平均: {np.mean(x_test):.4f}\")\n",
        "print(f\"出力平均: {np.mean(output_test):.4f}\")\n",
        "print(f\"残差平均: {np.mean(residual):.4f}\")\n",
        "print(\"⇒ 残差学習により、恒等写像からの小さな変化を学習\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDZAV8KR1Bkg",
        "outputId": "88a2c239-b48d-4682-a530-670a18c7a80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BasicBlockテスト ===\n",
            "入力形状: (2, 32, 32, 3)\n",
            "BasicBlock出力形状: (2, 32, 32, 64)\n",
            "\n",
            "=== SimpleResNet ===\n",
            "ResNet出力形状: (2, 10)\n",
            "出力例: [ 0.88414622 -0.03603872  1.18273422 -0.09054755 -1.17715313]\n",
            "\n",
            "=== 残差接続の効果確認 ===\n",
            "入力平均: 0.0114\n",
            "出力平均: 0.5692\n",
            "残差平均: 0.5579\n",
            "⇒ 残差学習により、恒等写像からの小さな変化を学習\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet18"
      ],
      "metadata": {
        "id": "X2U62DBk2-XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# デバイスの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"使用デバイス: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eESpCeZ6tGS",
        "outputId": "95c3e2a4-a0ee-4674-a0cf-22c35036d4dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データの前処理設定\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "metadata": {
        "id": "RxTZWTbE7nbg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10データセットの読み込み\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform_train\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# クラス名定義\n",
        "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\",\n",
        "           \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
      ],
      "metadata": {
        "id": "FCzGTCQN8UUS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNetモデルの読み込み（事前学習済みモデル）\n",
        "from torchvision import models\n",
        "\n",
        "# ResNet18を使用\n",
        "model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmFPOJiS9NVb",
        "outputId": "7e68f92d-c97f-4fbd-a519-56ff75797102"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10は10クラスなので、最終層を追加\n",
        "num_classes = 10\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes) # 全結合層\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "TygjKa8W9lrh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失関数と最適化手法の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "schedular = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)"
      ],
      "metadata": {
        "id": "29P-2O6D91OZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習関数\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "    for inputs, targets in progress_bar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"loss\": running_loss / (progress_bar.n + 1),\n",
        "            \"acc\": 100. * correct / total\n",
        "        })\n",
        "\n",
        "    return running_loss / len(dataloader), 100 * correct / total"
      ],
      "metadata": {
        "id": "bPk9y8o6-Mgn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 検証関数\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
        "        for inputs, targets in progress_bar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                \"loss\": running_loss / (progress_bar.n + 1),\n",
        "                \"acc\": 100. * correct / total\n",
        "            })\n",
        "\n",
        "    return running_loss / len(dataloader), 100. * correct / total\n"
      ],
      "metadata": {
        "id": "ABYPKmDw_ZiT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習の実行\n",
        "num_epochs = 10\n",
        "best_acc = 0\n",
        "\n",
        "print(\"学習開始...\")\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    train_loss, train_acc = train_epoch(model, trainloader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = validate(model, testloader, criterion, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Validate Loss: {val_loss:.4f}, Validate Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    schedular.step()\n",
        "\n",
        "    # ベストモデルの保存\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"best_acc\": best_acc,\n",
        "        }, \"best_resnet_model.pth\")\n",
        "        print(f\"ベストモデルを保存しました (Acc: {best_acc:.2f}%)\")\n",
        "\n",
        "print(f\"\\n学習完了 ベスト精度: {best_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj7wVjKGAjNt",
        "outputId": "7bb70c30-02b4-4c61-e81e-f40f1e78dbdf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習開始...\n",
            "\n",
            "Epoch 1/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 15.86it/s, loss=1.31, auc=53.6]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 34.29it/s, loss=0.967, acc=66.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3092, Train Acc: 53.57%\n",
            "Validate Loss: 0.9667, Validate Acc: 66.08%\n",
            "ベストモデルを保存しました (Acc: 66.08%)\n",
            "\n",
            "Epoch 2/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.93it/s, loss=0.896, auc=68.7]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 28.81it/s, loss=0.821, acc=72.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.8962, Train Acc: 68.69%\n",
            "Validate Loss: 0.7798, Validate Acc: 72.58%\n",
            "ベストモデルを保存しました (Acc: 72.58%)\n",
            "\n",
            "Epoch 3/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 16.00it/s, loss=0.778, auc=72.7]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 28.15it/s, loss=0.701, acc=75.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7776, Train Acc: 72.69%\n",
            "Validate Loss: 0.7013, Validate Acc: 75.60%\n",
            "ベストモデルを保存しました (Acc: 75.60%)\n",
            "\n",
            "Epoch 4/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.89it/s, loss=0.698, auc=75.8]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 26.29it/s, loss=0.659, acc=77.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6964, Train Acc: 75.76%\n",
            "Validate Loss: 0.6524, Validate Acc: 77.30%\n",
            "ベストモデルを保存しました (Acc: 77.30%)\n",
            "\n",
            "Epoch 5/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.89it/s, loss=0.646, auc=77.4]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 30.59it/s, loss=0.639, acc=78.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6447, Train Acc: 77.39%\n",
            "Validate Loss: 0.6267, Validate Acc: 78.30%\n",
            "ベストモデルを保存しました (Acc: 78.30%)\n",
            "\n",
            "Epoch 6/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.64it/s, loss=0.6, auc=78.9]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 36.28it/s, loss=0.612, acc=79.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5989, Train Acc: 78.93%\n",
            "Validate Loss: 0.6000, Validate Acc: 79.66%\n",
            "ベストモデルを保存しました (Acc: 79.66%)\n",
            "\n",
            "Epoch 7/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, loss=0.566, auc=79.9]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 39.36it/s, loss=0.581, acc=79.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5664, Train Acc: 79.89%\n",
            "Validate Loss: 0.5756, Validate Acc: 79.86%\n",
            "ベストモデルを保存しました (Acc: 79.86%)\n",
            "\n",
            "Epoch 8/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 16.20it/s, loss=0.54, auc=81.1]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 40.25it/s, loss=0.579, acc=80.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5390, Train Acc: 81.08%\n",
            "Validate Loss: 0.5614, Validate Acc: 80.85%\n",
            "ベストモデルを保存しました (Acc: 80.85%)\n",
            "\n",
            "Epoch 9/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.32it/s, loss=0.509, auc=82.2]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 39.62it/s, loss=0.582, acc=80.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5072, Train Acc: 82.23%\n",
            "Validate Loss: 0.5588, Validate Acc: 80.77%\n",
            "\n",
            "Epoch 10/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 16.19it/s, loss=0.489, auc=82.9]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 40.03it/s, loss=0.553, acc=81.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4875, Train Acc: 82.92%\n",
            "Validate Loss: 0.5416, Validate Acc: 81.13%\n",
            "ベストモデルを保存しました (Acc: 81.13%)\n",
            "\n",
            "学習完了 ベスト精度: 81.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CV2fky90B3_j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}