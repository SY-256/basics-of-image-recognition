{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPytrIt4mPz/tmlICEM/Mv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SY-256/basics-of-image-recognition/blob/main/chapter03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h7TfWl4lvAW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58bb8e37-76a8-4499-d72a-ea4ea4976260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 畳み込みニューラルネットワーク"
      ],
      "metadata": {
        "id": "ZiYDeElfkUhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/colab-notebooks/basics-of-image-recognition/\""
      ],
      "metadata": {
        "id": "_m1WAKlGvtsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def im2col(img, h, w, stride=1, pad=0):\n",
        "    \"\"\"\n",
        "    畳み込みフィルタ\n",
        "    img: (B, C, H, W)\n",
        "    h: kernel size\n",
        "    w: kernel width\n",
        "    \"\"\"\n",
        "    B, C, H, W = img.shape\n",
        "    img = np.pad(img, [(0, 0), (0, 0), (pad, pad), (pad, pad)], \"constant\")\n",
        "    out_h = (H + 2*pad - h)//stride + 1\n",
        "    out_w = (W + 2*pad - w)//stride + 1\n",
        "\n",
        "    out = np.zeros((B, C, h, w, out_h, out_w))\n",
        "\n",
        "    for y in range(h):\n",
        "        y_ = y + stride*out_h\n",
        "        for x in range(w):\n",
        "            x_ = x + stride*out_w\n",
        "            out[:, :, y, x, :, :] = img[:, :, y:y_:stride, x:x_:stride]\n",
        "\n",
        "    out = out.transpose(0, 4, 5, 1, 2, 3).reshape(B*out_h*out_w, -1)\n",
        "    return out\n",
        "\n",
        "class Conv2D:\n",
        "    \"\"\"\n",
        "    in_ch: number of input channels\n",
        "    out_ch: number of output channels\n",
        "    h, w: kernel size\n",
        "    stride: stride of conv process\n",
        "    pad: padding size\n",
        "    img: input image (B, in_ch, H, W)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch, h, w, stride=1, pad=0):\n",
        "        self.out_ch = out_ch\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "        self.filters = np.random.randn(out_ch, in_ch, h, w)\n",
        "        self.bias = np.zeros(out_ch)\n",
        "\n",
        "    def forward(self, img):\n",
        "        B, in_ch, H, W = img.shape\n",
        "        out_ch, in_ch, h, w = self.filters.shape\n",
        "\n",
        "        img = im2col(img, h, w, self.stride, self.pad)\n",
        "        filters = self.filters.reshape(out_ch, -1).T\n",
        "\n",
        "        out = np.dot(img, filters) + self.bias\n",
        "\n",
        "        out_h = 1 + int((H + 2*self.pad - h) / self.stride)\n",
        "        out_w = 1 + int((W + 2*self.pad - w) / self.stride)\n",
        "        out = out.reshape(B, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wBYmbMmEkfkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### edeg detection\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "img = Image.open(base_path + \"keyboard.png\").convert(\"L\")\n",
        "img = np.array(img, dtype=float) / 255\n",
        "img = img[np.newaxis, np.newaxis, :, :]\n",
        "conv = Conv2D(in_ch=1, out_ch=1, h=3, w=3, stride=1, pad=1)\n",
        "### horizontal edge detectio\n",
        "conv.filters[0, 0, :, :] = np.array([[-1, -2, -1], [0 ,0, 0], [1, 2, 1]])\n",
        "conv.filters[0, 0, :, :] = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "out = conv.forward(img)\n",
        "out = np.clip(out, 0, 1)\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(img[0, 0], cmap=\"gray\")\n",
        "plt.title(\"Input Image\")\n",
        "plt.subplot(122)\n",
        "plt.imshow(out[0, 0], cmap=\"gray\")\n",
        "plt.title(\"Output Image\")\n",
        "plt.savefig(base_path + \"convoled_output.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zju2EGznq9bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAP（グローバルアベレージプーリング）をスクラッチで"
      ],
      "metadata": {
        "id": "H90ikwJStdke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### GAP（グローバルアベレージプーリング）\n",
        "import numpy as np\n",
        "\n",
        "def global_average_poooling_2d(x):\n",
        "    \"\"\"\n",
        "    Global Average Pooling 2D\n",
        "\n",
        "    Args:\n",
        "        x: 入力テンソル（batch, hight, width, channels）または（height, width, chnnels）\n",
        "    Returns:\n",
        "        出力テンソル（batch_size, channels）または（channels,）\n",
        "    \"\"\"\n",
        "    if x.ndim == 4: # バッチあり\n",
        "        return np.mean(x, axis=(1,2))\n",
        "    elif x.ndim == 3: # バッチなしの場合\n",
        "        return np.mean(x, axis=(0, 1))\n",
        "    else:\n",
        "        raise ValueError(\"入力次元は3次元または4次元である必要があります\")\n",
        "\n",
        "def global_average_poooling_1d(x):\n",
        "    \"\"\"\n",
        "    Global Average Pooling 1D\n",
        "\n",
        "    Args:\n",
        "        x: 入力テンソル（batch_size, length, channels）または（lenght, channels）\n",
        "\n",
        "    Returns:\n",
        "        出力テンソル（batch_size, channels）または（channels,）\n",
        "    \"\"\"\n",
        "    if x.ndim == 3: # バッチあり\n",
        "        return np.mean(x, axis=1)\n",
        "    elif x.ndim == 2: # バッチなし\n",
        "        return np.mean(x, axis=0)\n",
        "    else:\n",
        "        raise ValueError(\"入力は2次元または3次元である必要があります\")\n",
        "\n",
        "class GlobalAveragePooling2D:\n",
        "    \"\"\"クラス版のGlobal Average Pooling 2D\"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.input_shape = x.shape\n",
        "        return global_average_poooling_2d(x)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        \"\"\"逆伝播の実装\"\"\"\n",
        "        if len(self.input_shape) == 4:\n",
        "            batch_size, height, width, channels = self.input_shape\n",
        "            # 勾配を元の形状に戻す（平均で割った値を全ピクセルに分散）\n",
        "            grad_input = np.zeros(self.input_shape)\n",
        "            for i in range(batch_size):\n",
        "                for c in range(channels):\n",
        "                    grad_input[i, :, :, c] = grad_output[i, c] / (height * width)\n",
        "\n",
        "        else:\n",
        "            height, width, channels = self.input_shape\n",
        "            grad_input = np.zeros(self.input_shape)\n",
        "            for c in range(channels):\n",
        "                grad_input[:, :, c] = grad_output[c] / (height * width)\n",
        "\n",
        "        return grad_input\n"
      ],
      "metadata": {
        "id": "Kwn_3cPku_RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Global Average Pooling 2D ===\")\n",
        "# 単一画像の場合（height=4, width=4, channels=3）\n",
        "x_2d = np.random.randn(4, 4, 3)\n",
        "print(f\"入力形状: {x_2d.shape}\")\n",
        "print(f\"入力値: {x_2d}\")\n",
        "\n",
        "output_2d = global_average_poooling_2d(x_2d)\n",
        "print(f\"出力形状: {output_2d.shape}\")\n",
        "print(f\"出力値: {output_2d}\")\n",
        "\n",
        "# バッチの場合（batch=2, height=4, width=4, channels=3）\n",
        "x_batch_2d = np.random.randn(2, 4, 4, 3)\n",
        "print(f\"\\n入力バッチ形状: {x_batch_2d.shape}\")\n",
        "\n",
        "output_batch_2d = global_average_poooling_2d(x_batch_2d)\n",
        "print(f\"バッチ出力形状: {output_batch_2d.shape}\")\n",
        "\n",
        "print(\"\\n==== クラス版 ====\")\n",
        "gap_layer = GlobalAveragePooling2D()\n",
        "\n",
        "x_test = np.random.randn(1, 3, 3, 2)\n",
        "output = gap_layer.forward(x_test)\n",
        "print(f\"入力形状: {x_test.shape}\")\n",
        "print(f\"出力形状: {output.shape}\")\n",
        "\n",
        "# 逆伝播のテスト\n",
        "grad_output = np.ones_like(output)\n",
        "grad_input = gap_layer.backward(grad_output)\n",
        "print(f\"勾配入力形状: {grad_input.shape}\")\n",
        "print(f\"勾配値の例: {grad_input[0, 0, 0, :]}\")\n"
      ],
      "metadata": {
        "id": "c3u6P_yduurO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47c4299-a141-4ff3-e89b-670702c41d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Global Average Pooling 2D ===\n",
            "入力形状: (4, 4, 3)\n",
            "入力値: [[[ 1.9216899   0.76574373  0.19227038]\n",
            "  [ 0.90747202 -1.00150843 -0.93774835]\n",
            "  [ 0.45887446  1.36584178 -0.61927072]\n",
            "  [ 0.66800848 -0.97647051 -0.8558606 ]]\n",
            "\n",
            " [[ 1.51556905 -0.81584812  1.353832  ]\n",
            "  [ 0.82094649 -1.34260133 -0.19318977]\n",
            "  [-0.7527346   1.99628424 -1.3232735 ]\n",
            "  [-0.76252744  1.4831022   1.13187252]]\n",
            "\n",
            " [[ 1.33507294  1.27968203  0.43559142]\n",
            "  [ 0.19062981  0.41805862 -0.30810173]\n",
            "  [-0.94957467 -0.17696031  0.8310906 ]\n",
            "  [ 0.57156049 -0.66808225 -1.60692287]]\n",
            "\n",
            " [[-1.21114089  1.37205759 -0.22141397]\n",
            "  [-0.19499464  0.24747499 -0.61352329]\n",
            "  [ 0.11728387  0.46471609  0.68810329]\n",
            "  [ 0.42640274  1.00966312 -0.35621508]]]\n",
            "出力形状: (3,)\n",
            "出力値: [ 0.31640863  0.33882209 -0.15017248]\n",
            "\n",
            "入力バッチ形状: (2, 4, 4, 3)\n",
            "バッチ出力形状: (2, 3)\n",
            "\n",
            "==== クラス版 ====\n",
            "入力形状: (1, 3, 3, 2)\n",
            "出力形状: (1, 2)\n",
            "勾配入力形状: (1, 3, 3, 2)\n",
            "勾配値の例: [0.11111111 0.11111111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 残差学習をスクラッチで"
      ],
      "metadata": {
        "id": "igfBbkAis3ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def relu(x):\n",
        "    \"\"\"ReLU活計化関数\"\"\"\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def conv2d(x, weights, bias=None, stride=1, padding=0):\n",
        "    \"\"\"2D畳み込み（簡易版）\"\"\"\n",
        "    batch_size, in_height, in_width, in_channels = x.shape\n",
        "    out_channels, kernel_h, kernel_w, _ = weights.shape\n",
        "\n",
        "    # パディング\n",
        "    if padding > 0:\n",
        "        x = np.pad(x, ((0, 0), (padding, padding), (padding, padding), (0, 0,)), \"constant\")\n",
        "\n",
        "    out_height = (x.shape[1] - kernel_h) // stride + 1\n",
        "    out_width = (x.shape[2] - kernel_w) // stride + 1\n",
        "\n",
        "    output = np.zeros((batch_size, out_height, out_width, out_channels))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for oc in range(out_channels):\n",
        "            for oh in range(out_height):\n",
        "                for ow in range(out_width):\n",
        "                    h_start = oh * stride\n",
        "                    w_start = ow * stride\n",
        "                    patch = x[b, h_start:h_start+kernel_h, w_start:w_start+kernel_w, :]\n",
        "                    output[b, oh, ow, oc] = np.sum(patch * weights[oc]) + (bias[oc] if bias is not None else 0)\n",
        "    return output\n",
        "\n",
        "def batch_norm(x, gamma, beta, eps=1e-5):\n",
        "    \"\"\"バッチ正規化\"\"\"\n",
        "    mean = np.mean(x, axis=(0, 1, 2), keepdims=True)\n",
        "    var = np.var(x, axis=(0, 1, 2), keepdims=True)\n",
        "    x_norm = (x - mean) / np.sqrt(var + eps)\n",
        "    return gamma * x_norm + beta\n",
        "\n",
        "class BasicBlock:\n",
        "    \"\"\"ResNetの基本ブロック（2層）\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # 畳み込み層の重み初期化\n",
        "        self.conv1d_weights = np.random.randn(out_channels, 3, 3, in_channels) * 0.1\n",
        "        self.conv1d_bias = np.zeros(out_channels)\n",
        "\n",
        "        self.conv2d_weights = np.random.randn(out_channels, 3, 3, out_channels) * 0.1\n",
        "        self.conv2d_bias = np.zeros(out_channels)\n",
        "\n",
        "        # バッチ正規化パラメータ\n",
        "        self.bn1_gamma = np.ones(out_channels)\n",
        "        self.bn1_beta = np.zeros(out_channels)\n",
        "        self.bn2_gamma = np.ones(out_channels)\n",
        "        self.bn2_beta = np.zeros(out_channels)\n",
        "\n",
        "        # ショートカット接続（チャネル数が変わる場合）\n",
        "        self.use_shortcut_conv = (stride != 1) or (in_channels != out_channels)\n",
        "        if self.use_shortcut_conv:\n",
        "            self.shortcut_weights = np.random.randn(out_channels, 1, 1, in_channels) * 0.1\n",
        "            self.shortcut_bias = np.zeros(out_channels)\n",
        "            self.shortcut_bn_gamma = np.ones(out_channels)\n",
        "            self.shortcut_bn_beta = np.zeros(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"順伝播\"\"\"\n",
        "        identity = x\n",
        "\n",
        "        # メインパス\n",
        "        out = conv2d(x, self.conv1d_weights, self.conv1d_bias, stride=self.stride, padding=1)\n",
        "        out = batch_norm(out, self.bn1_gamma, self.bn1_beta)\n",
        "        out = relu(out)\n",
        "\n",
        "        out = conv2d(out, self.conv2d_weights, self.conv2d_bias, stride=1, padding=1)\n",
        "        out = batch_norm(out, self.bn2_gamma, self.bn2_beta)\n",
        "\n",
        "        # ショートカット接続\n",
        "        if self.use_shortcut_conv:\n",
        "            identity = conv2d(identity, self.shortcut_weights, self.shortcut_bias,\n",
        "                              stride=self.stride, padding=0)\n",
        "            identity = batch_norm(identity, self.shortcut_bn_gamma, self.shortcut_bn_beta)\n",
        "\n",
        "        # 残差接続\n",
        "        out = out + identity\n",
        "        out = relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SimpleResNet:\n",
        "    \"\"\"シンプルなResNet\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # 初期畳み込み層\n",
        "        self.conv1d_weights = np.random.randn(64, 7, 7, 3) * 0.1\n",
        "        self.conv1d_bias = np.zeros(64)\n",
        "        self.bn1_gamma = np.ones(64)\n",
        "        self.bn1_beta = np.zeros(64)\n",
        "\n",
        "        # 残差ブロック\n",
        "        self.layer1 = [BasicBlock(64, 64) for _ in range(2)]\n",
        "        self.layer2 = [BasicBlock(64, 128, stride=2)] + [BasicBlock(128, 128) for _ in range(1)]\n",
        "        self.layer3 = [BasicBlock(128, 256, stride=2)] + [BasicBlock(256, 256) for _ in range(1)]\n",
        "\n",
        "        # 分類層\n",
        "        self.fc_weights = np.random.randn(256, num_classes) * 0.1\n",
        "        self.fc_bias = np.zeros(num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"順伝播\"\"\"\n",
        "        # 初期畳み込み\n",
        "        out = conv2d(x, self.conv1d_weights, self.conv1d_bias, stride=2, padding=3)\n",
        "        out = batch_norm(out, self.bn1_gamma, self.bn1_beta)\n",
        "        out = relu(out)\n",
        "\n",
        "        # 残差ブロック\n",
        "        for block in self.layer1:\n",
        "            out = block.forward(out)\n",
        "\n",
        "        for block in self.layer2:\n",
        "            out = block.forward(out)\n",
        "\n",
        "        for block in self.layer3:\n",
        "            out = block.forward(out)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        out = np.mean(out, axis=(1, 2))\n",
        "\n",
        "        # 全結合層\n",
        "        out = np.dot(out, self.fc_weights) + self.fc_bias\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "iUNsmYLUtpB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータ\n",
        "batch_size = 2\n",
        "x = np.random.randn(batch_size, 32, 32, 3)\n",
        "\n",
        "print(\"=== BasicBlockテスト ===\")\n",
        "basic_block = BasicBlock(3, 64, stride=1)\n",
        "output_basic = basic_block.forward(x)\n",
        "print(f\"入力形状: {x.shape}\")\n",
        "print(f\"BasicBlock出力形状: {output_basic.shape}\")\n",
        "\n",
        "print(\"\\n=== SimpleResNet ===\")\n",
        "model = SimpleResNet(num_classes=10)\n",
        "output = model.forward(x)\n",
        "print(f\"ResNet出力形状: {output.shape}\")\n",
        "print(f\"出力例: {output[0][:5]}\") # 最初のサンプルの最初の5クラス\n",
        "\n",
        "# 残差接続の効果を確認\n",
        "print(\"\\n=== 残差接続の効果確認 ===\")\n",
        "# 同じ入力に対して複数回実行（実際の学習では勾配が流れやすくなる）\n",
        "x_test = np.random.randn(1, 8, 8, 64)\n",
        "block_test = BasicBlock(64, 64)\n",
        "\n",
        "# 入力と出力の差分（残差）を確認\n",
        "output_test = block_test.forward(x_test)\n",
        "residual = output_test - x_test # これが学習される残差\n",
        "print(f\"入力平均: {np.mean(x_test):.4f}\")\n",
        "print(f\"出力平均: {np.mean(output_test):.4f}\")\n",
        "print(f\"残差平均: {np.mean(residual):.4f}\")\n",
        "print(\"⇒ 残差学習により、恒等写像からの小さな変化を学習\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDZAV8KR1Bkg",
        "outputId": "88a2c239-b48d-4682-a530-670a18c7a80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BasicBlockテスト ===\n",
            "入力形状: (2, 32, 32, 3)\n",
            "BasicBlock出力形状: (2, 32, 32, 64)\n",
            "\n",
            "=== SimpleResNet ===\n",
            "ResNet出力形状: (2, 10)\n",
            "出力例: [ 0.88414622 -0.03603872  1.18273422 -0.09054755 -1.17715313]\n",
            "\n",
            "=== 残差接続の効果確認 ===\n",
            "入力平均: 0.0114\n",
            "出力平均: 0.5692\n",
            "残差平均: 0.5579\n",
            "⇒ 残差学習により、恒等写像からの小さな変化を学習\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet18"
      ],
      "metadata": {
        "id": "X2U62DBk2-XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# デバイスの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"使用デバイス: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eESpCeZ6tGS",
        "outputId": "95c3e2a4-a0ee-4674-a0cf-22c35036d4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データの前処理設定\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "metadata": {
        "id": "RxTZWTbE7nbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10データセットの読み込み\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform_train\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# クラス名定義\n",
        "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\",\n",
        "           \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
      ],
      "metadata": {
        "id": "FCzGTCQN8UUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNetモデルの読み込み（事前学習済みモデル）\n",
        "from torchvision import models\n",
        "\n",
        "# ResNet18を使用\n",
        "model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmFPOJiS9NVb",
        "outputId": "7e68f92d-c97f-4fbd-a519-56ff75797102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10は10クラスなので、最終層を追加\n",
        "num_classes = 10\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes) # 全結合層\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "TygjKa8W9lrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失関数と最適化手法の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "schedular = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)"
      ],
      "metadata": {
        "id": "29P-2O6D91OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習関数\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "    for inputs, targets in progress_bar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"loss\": running_loss / (progress_bar.n + 1),\n",
        "            \"acc\": 100. * correct / total\n",
        "        })\n",
        "\n",
        "    return running_loss / len(dataloader), 100 * correct / total"
      ],
      "metadata": {
        "id": "bPk9y8o6-Mgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 検証関数\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
        "        for inputs, targets in progress_bar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                \"loss\": running_loss / (progress_bar.n + 1),\n",
        "                \"acc\": 100. * correct / total\n",
        "            })\n",
        "\n",
        "    return running_loss / len(dataloader), 100. * correct / total\n"
      ],
      "metadata": {
        "id": "ABYPKmDw_ZiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習の実行\n",
        "num_epochs = 10\n",
        "best_acc = 0\n",
        "\n",
        "print(\"学習開始...\")\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    train_loss, train_acc = train_epoch(model, trainloader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = validate(model, testloader, criterion, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Validate Loss: {val_loss:.4f}, Validate Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    schedular.step()\n",
        "\n",
        "    # ベストモデルの保存\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"best_acc\": best_acc,\n",
        "        }, \"best_resnet_model.pth\")\n",
        "        print(f\"ベストモデルを保存しました (Acc: {best_acc:.2f}%)\")\n",
        "\n",
        "print(f\"\\n学習完了 ベスト精度: {best_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj7wVjKGAjNt",
        "outputId": "7bb70c30-02b4-4c61-e81e-f40f1e78dbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習開始...\n",
            "\n",
            "Epoch 1/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 15.86it/s, loss=1.31, auc=53.6]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 34.29it/s, loss=0.967, acc=66.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3092, Train Acc: 53.57%\n",
            "Validate Loss: 0.9667, Validate Acc: 66.08%\n",
            "ベストモデルを保存しました (Acc: 66.08%)\n",
            "\n",
            "Epoch 2/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.93it/s, loss=0.896, auc=68.7]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 28.81it/s, loss=0.821, acc=72.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.8962, Train Acc: 68.69%\n",
            "Validate Loss: 0.7798, Validate Acc: 72.58%\n",
            "ベストモデルを保存しました (Acc: 72.58%)\n",
            "\n",
            "Epoch 3/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 16.00it/s, loss=0.778, auc=72.7]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 28.15it/s, loss=0.701, acc=75.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7776, Train Acc: 72.69%\n",
            "Validate Loss: 0.7013, Validate Acc: 75.60%\n",
            "ベストモデルを保存しました (Acc: 75.60%)\n",
            "\n",
            "Epoch 4/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.89it/s, loss=0.698, auc=75.8]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 26.29it/s, loss=0.659, acc=77.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6964, Train Acc: 75.76%\n",
            "Validate Loss: 0.6524, Validate Acc: 77.30%\n",
            "ベストモデルを保存しました (Acc: 77.30%)\n",
            "\n",
            "Epoch 5/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.89it/s, loss=0.646, auc=77.4]\n",
            "Validation: 100%|██████████| 100/100 [00:03<00:00, 30.59it/s, loss=0.639, acc=78.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6447, Train Acc: 77.39%\n",
            "Validate Loss: 0.6267, Validate Acc: 78.30%\n",
            "ベストモデルを保存しました (Acc: 78.30%)\n",
            "\n",
            "Epoch 6/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.64it/s, loss=0.6, auc=78.9]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 36.28it/s, loss=0.612, acc=79.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5989, Train Acc: 78.93%\n",
            "Validate Loss: 0.6000, Validate Acc: 79.66%\n",
            "ベストモデルを保存しました (Acc: 79.66%)\n",
            "\n",
            "Epoch 7/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.40it/s, loss=0.566, auc=79.9]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 39.36it/s, loss=0.581, acc=79.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5664, Train Acc: 79.89%\n",
            "Validate Loss: 0.5756, Validate Acc: 79.86%\n",
            "ベストモデルを保存しました (Acc: 79.86%)\n",
            "\n",
            "Epoch 8/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 16.20it/s, loss=0.54, auc=81.1]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 40.25it/s, loss=0.579, acc=80.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5390, Train Acc: 81.08%\n",
            "Validate Loss: 0.5614, Validate Acc: 80.85%\n",
            "ベストモデルを保存しました (Acc: 80.85%)\n",
            "\n",
            "Epoch 9/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:23<00:00, 16.32it/s, loss=0.509, auc=82.2]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 39.62it/s, loss=0.582, acc=80.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5072, Train Acc: 82.23%\n",
            "Validate Loss: 0.5588, Validate Acc: 80.77%\n",
            "\n",
            "Epoch 10/10\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 391/391 [00:24<00:00, 16.19it/s, loss=0.489, auc=82.9]\n",
            "Validation: 100%|██████████| 100/100 [00:02<00:00, 40.03it/s, loss=0.553, acc=81.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4875, Train Acc: 82.92%\n",
            "Validate Loss: 0.5416, Validate Acc: 81.13%\n",
            "ベストモデルを保存しました (Acc: 81.13%)\n",
            "\n",
            "学習完了 ベスト精度: 81.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SE-ResNet\n",
        "- Gloval Average Pooling + MLP（2層全結合層）\n",
        "\n",
        "**特徴**\n",
        "1. SEBlock（Squeeze-and-Excitation Block）\n",
        "\n",
        "    Global Average Poolingでチャネルごとの特徴を圧縮\n",
        "    2つの全結合層（削減→復元）でチャネル間の依存関係を学習\n",
        "    Sigmoidで0-1の重みを生成し、元の特徴マップにスケーリング\n",
        "\n",
        "2. SEBasicBlock / SEBottleneck\n",
        "\n",
        "    通常のResNetブロックにSEBlockを追加\n",
        "    ResNet-18/34用のBasicBlockと、ResNet-50以上用のBottleneckに対応\n",
        "\n",
        "3. SE-ResNet本体\n",
        "\n",
        "    se_resnet18、se_resnet34、se_resnet50の3つのバリエーション\n",
        "    CIFAR-10での学習例（10クラス分類）"
      ],
      "metadata": {
        "id": "CV2fky90B3_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import os"
      ],
      "metadata": {
        "id": "OooypLy25PIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeeze-and-Excitation Block\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
        "        self.excitation = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        # Sequeeze: Gloval Average Pooling\n",
        "        y = self.squeeze(x).view(b, c)\n",
        "        # Excitation: FC -> ReLU -> FC -> Sigmoid\n",
        "        y = self.excitation(y).view(b, c, 1, 1)\n",
        "        # Scale\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class SEBasickBlock(nn.Module):\n",
        "    \"\"\"SE-ResNetの基本ブロック(ResNet-18/34用)\"\"\"\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsampling=None, reduction=16):\n",
        "        super(SEBasickBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.se = SEBlock(out_channels, reduction)\n",
        "        self.downsampling = downsampling\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # SE Block\n",
        "        out = self.se(out)\n",
        "\n",
        "        if self.downsampling is not None:\n",
        "            identity = self.downsampling(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SEBottleneck(nn.Module):\n",
        "    \"\"\"SE-ResNetのボトルネックブロック(ResNet-50/101/152用)\"\"\"\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_cahnnels, out_channels, stride=1, downsampling=None, reduction=16):\n",
        "        super(SEBottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_cahnnels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                                stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.se = SEBlock(out_channels * self.expansion, reduction)\n",
        "        self.downsampling = downsampling\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        # SE Block\n",
        "        out = self.se(out)\n",
        "\n",
        "        if self.donsampling is not None:\n",
        "            identity = self.downsampling(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SEResNet(nn.Module):\n",
        "    \"\"\"SE-ResNet\"\"\"\n",
        "    def __init__(self, block, layers, num_classes=10, reduction=16):\n",
        "        super(SEResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.reduction = reduction\n",
        "\n",
        "        # 初期層\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # ResNetレイヤー\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # 分類層\n",
        "        self.avggpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        # 重みの初期化\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsampling = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsampling = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsampling, self.reduction))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels, reduction=self.reduction))\n",
        "        self.block.ex\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "APrOIyQ45w99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet"
      ],
      "metadata": {
        "id": "202W8qeOFaMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    \"\"\"Swish activation function (also known as SiLU)\"\"\"\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
        "    def __init__(self, in_channels: int, se_ratio: float = 0.25):\n",
        "        super().__init__()\n",
        "        squeeze_channels = max(1, int(in_channels * se_ratio))\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, squeeze_channels, 1),\n",
        "            Swish(),\n",
        "            nn.Conv2d(squeeze_channels, in_channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.se(x)\n",
        "\n",
        "\n",
        "class MBConvBlock(nn.Module):\n",
        "    \"\"\"Mobile Inverted Bottleneck Convolution Block\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size: int,\n",
        "        stride: int,\n",
        "        expand_ratio: int,\n",
        "        se_ratio: float = 0.25,\n",
        "        drop_connect_rate: float = 0.2\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.stride = stride\n",
        "        self.use_residual = (stride == 1 and in_channels == out_channels)\n",
        "        self.drop_connect_rate = drop_connect_rate\n",
        "\n",
        "        # Expansion phase\n",
        "        expanded_channels = in_channels * expand_ratio\n",
        "        self.expand = None\n",
        "        if expand_ratio != 1:\n",
        "            self.expand = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, expanded_channels, 1, bias=False),\n",
        "                nn.BatchNorm2d(expanded_channels),\n",
        "                Swish()\n",
        "            )\n",
        "\n",
        "        # Depthwise convolution\n",
        "        self.depthwise = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                expanded_channels,\n",
        "                expanded_channels,\n",
        "                kernel_size,\n",
        "                stride=stride,\n",
        "                padding=kernel_size // 2,\n",
        "                groups=expanded_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(expanded_channels),\n",
        "            Swish()\n",
        "        )\n",
        "\n",
        "        # Squeeze-and-Excitation\n",
        "        self.se = SEBlock(expanded_channels, se_ratio)\n",
        "\n",
        "        # Output projection\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(expanded_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        # Expansion\n",
        "        if self.expand is not None:\n",
        "            x = self.expand(x)\n",
        "\n",
        "        # Depthwise + SE\n",
        "        x = self.depthwise(x)\n",
        "        x = self.se(x)\n",
        "\n",
        "        # Projection\n",
        "        x = self.project(x)\n",
        "\n",
        "        # Skip connection with drop connect\n",
        "        if self.use_residual:\n",
        "            if self.training and self.drop_connect_rate > 0:\n",
        "                x = self._drop_connect(x, self.drop_connect_rate)\n",
        "            x = x + identity\n",
        "\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _drop_connect(x, drop_rate):\n",
        "        \"\"\"Drop connect (stochastic depth)\"\"\"\n",
        "        if not x.requires_grad:\n",
        "            return x\n",
        "        keep_prob = 1 - drop_rate\n",
        "        random_tensor = keep_prob + torch.rand(\n",
        "            (x.shape[0], 1, 1, 1), dtype=x.dtype, device=x.device\n",
        "        )\n",
        "        random_tensor.floor_()\n",
        "        return x.div(keep_prob) * random_tensor\n",
        "\n",
        "\n",
        "class EfficientNet(nn.Module):\n",
        "    \"\"\"EfficientNet implementation\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        width_mult: float = 1.0,\n",
        "        depth_mult: float = 1.0,\n",
        "        dropout_rate: float = 0.2,\n",
        "        drop_connect_rate: float = 0.2,\n",
        "        num_classes: int = 1000\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Building blocks configuration: [expand_ratio, channels, repeats, stride, kernel_size]\n",
        "        blocks_config = [\n",
        "            [1, 16, 1, 1, 3],   # Stage 1\n",
        "            [6, 24, 2, 2, 3],   # Stage 2\n",
        "            [6, 40, 2, 2, 5],   # Stage 3\n",
        "            [6, 80, 3, 2, 3],   # Stage 4\n",
        "            [6, 112, 3, 1, 5],  # Stage 5\n",
        "            [6, 192, 4, 2, 5],  # Stage 6\n",
        "            [6, 320, 1, 1, 3],  # Stage 7\n",
        "        ]\n",
        "\n",
        "        # Stem\n",
        "        out_channels = self._round_filters(32, width_mult)\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, out_channels, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            Swish()\n",
        "        )\n",
        "\n",
        "        # Building blocks\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        total_blocks = sum([self._round_repeats(config[2], depth_mult)\n",
        "                           for config in blocks_config])\n",
        "        block_idx = 0\n",
        "\n",
        "        in_channels = out_channels\n",
        "        for expand_ratio, channels, repeats, stride, kernel_size in blocks_config:\n",
        "            out_channels = self._round_filters(channels, width_mult)\n",
        "            repeats = self._round_repeats(repeats, depth_mult)\n",
        "\n",
        "            for i in range(repeats):\n",
        "                # Drop connect rate increases linearly\n",
        "                drop_rate = drop_connect_rate * block_idx / total_blocks\n",
        "\n",
        "                self.blocks.append(\n",
        "                    MBConvBlock(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=kernel_size,\n",
        "                        stride=stride if i == 0 else 1,\n",
        "                        expand_ratio=expand_ratio,\n",
        "                        drop_connect_rate=drop_rate\n",
        "                    )\n",
        "                )\n",
        "                in_channels = out_channels\n",
        "                block_idx += 1\n",
        "\n",
        "        # Head\n",
        "        final_channels = self._round_filters(1280, width_mult)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, final_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(final_channels),\n",
        "            Swish(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Linear(final_channels, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.head(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _round_filters(filters: int, width_mult: float, divisor: int = 8) -> int:\n",
        "        \"\"\"Round number of filters based on width multiplier\"\"\"\n",
        "        filters *= width_mult\n",
        "        new_filters = max(divisor, int(filters + divisor / 2) // divisor * divisor)\n",
        "        if new_filters < 0.9 * filters:\n",
        "            new_filters += divisor\n",
        "        return int(new_filters)\n",
        "\n",
        "    @staticmethod\n",
        "    def _round_repeats(repeats: int, depth_mult: float) -> int:\n",
        "        \"\"\"Round number of repeats based on depth multiplier\"\"\"\n",
        "        return int(math.ceil(depth_mult * repeats))\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Initialize weights\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "def efficientnet_b0(num_classes: int = 10000):\n",
        "    \"\"\"EfficientNet-B0\"\"\"\n",
        "    return EfficientNet(\n",
        "        width_mult=1.0,\n",
        "        depth_mult=1.0,\n",
        "        dropout_rate=0.2,\n",
        "        num_classes=num_classes\n",
        "    )\n",
        "\n",
        "def efficientnet_b1(num_classes: int = 10000):\n",
        "    \"\"\"EfficientNet-B1\"\"\"\n",
        "    return EfficientNet(\n",
        "        width_mult=1.1,\n",
        "        depth_mult=1.2,\n",
        "        dropout_rate=0.3,\n",
        "        num_classes=num_classes\n",
        "    )\n",
        "\n",
        "def efficientnet_b2(num_classes: int = 10000):\n",
        "    \"\"\"EfficientNet-B2\"\"\"\n",
        "    return EfficientNet(\n",
        "        width_mult=1.1,\n",
        "        depth_mult=1.2,\n",
        "        dropout_rate=0.3,\n",
        "        num_classes=num_classes\n",
        "    )\n",
        "\n",
        "def efficientnet_b3(num_classes: int = 10000):\n",
        "    \"\"\"EfficientNet-B3\"\"\"\n",
        "    return EfficientNet(\n",
        "        width_mult=1.2,\n",
        "        depth_mult=1.4,\n",
        "        dropout_rate=0.3,\n",
        "        num_classes=num_classes\n",
        "    )"
      ],
      "metadata": {
        "id": "u6o6O1k5NgWb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model = efficientnet_b0(num_classes=10)\n",
        "x = torch.randn(2, 3, 224, 224)\n",
        "y = model(x)\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {y.shape}\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ],
      "metadata": {
        "id": "gxmTOk3DayjU",
        "outputId": "b2204c2d-7009-4e97-e35d-3c5ef5d2064e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 3, 224, 224])\n",
            "Output shape: torch.Size([2, 10])\n",
            "Total parameters: 7,155,658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデル学習"
      ],
      "metadata": {
        "id": "nWC1RbNoejUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YGTqeD7ENvbJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter:\n",
        "    \"\"\"計算と平均値の保存\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "bVjkmUilOcKn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    \"\"\"1エポックの学習\"\"\"\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\")\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct = predicted.eq(labels).sum().item()\n",
        "        accuracy = correct / batch_size\n",
        "\n",
        "        # Update metrics\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        accuracies.update(accuracy, batch_size)\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{losses.avg:.4f}\",\n",
        "            \"acc\": f\"{accuracies.avg:.4f}\"\n",
        "        })\n",
        "\n",
        "    return losses.avg, accuracies.avg"
      ],
      "metadata": {
        "id": "hKf_IDghO_Ie"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, val_loader, criterion, device, epoch):\n",
        "    \"\"\"検証\"\"\"\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch} [Val]\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct = predicted.eq(labels).sum().item()\n",
        "            accuracy = correct / batch_size\n",
        "\n",
        "            # Update metrics\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            accuracies.update(accuracy, batch_size)\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                \"loss\": f\"{losses.avg:.4f}\",\n",
        "                \"acc\": f\"{accuracies.avg:.4f}\"\n",
        "            })\n",
        "\n",
        "    return losses.avg, accuracies.avg"
      ],
      "metadata": {
        "id": "l04Bl9WDQffG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        num_epochs,\n",
        "        learning_rate,\n",
        "        device,\n",
        "        save_dir=\"checkpoints\"\n",
        "):\n",
        "    \"\"\"学習メイン関数\"\"\"\n",
        "    os.mkdir(save_dir, exist_ok=True)\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    schedular = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    # History\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, device, epoch\n",
        "        )\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = validate(\n",
        "            model, val_loader, criterion, device, epoch\n",
        "        )\n",
        "\n",
        "        # Update scheduler\n",
        "        schedular.step()\n",
        "\n",
        "        # Save history\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        print(f\"\\nEpoch {epoch}/{num_epochs} - {epoch_time:.2f}s\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "        print(f\"Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}\\n\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save({\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"val_acc\": val_acc,\n",
        "            }, os.path.join(save_dir, \"best_model.pth\"))\n",
        "            print(f\"Best model saved with val_acc: {val_acc:.4f}\\n\")\n",
        "\n",
        "        # Save latest model\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"history\": history,\n",
        "        }, os.path.join(save_dir, \"latest_model.pth\"))\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "jJTVaNbeR1Tt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, save_path=\"training_history.png\"):\n",
        "    \"\"\"学習履歴のプロット\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Loss\n",
        "    ax1.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "    ax1.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.set_title(\"Training and Validation Loss\")\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Accuracy\n",
        "    ax2.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
        "    ax2.plot(history[\"val_acc\"], label=\"Val Acc\")\n",
        "    ax2.set_xlabel(\"Epoch\")\n",
        "    ax2.set_ylabel(\"Accuracy\")\n",
        "    ax2.set_title(\"Training and Validation Accuracy\")\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
        "    print(f\"Training history saved to {save_path}\")"
      ],
      "metadata": {
        "id": "Gs7WAYYWUpPf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfOSK5hXV35h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}